From 9f9e3db9d80be17d6fc9be48b6d8745c971fca99 Mon Sep 17 00:00:00 2001
From: vboxsync <vboxsync@cfe28804-0f27-0410-a406-dd0f0b0b656f>
Date: Wed, 29 Jul 2020 10:02:13 +0000
Subject: [PATCH] IPRT/memobj-r0drv*: Change the fExecutable flag to W^X
 semantics where possible (linux 5.8+ only atm).  Linux 5.8 adjustments. 
 bugref:9801

git-svn-id: http://www.virtualbox.org/svn/vbox@85504 cfe28804-0f27-0410-a406-dd0f0b0b656f
---
 trunk/include/iprt/memobj.h                   | 30 ++++--
 .../Runtime/r0drv/linux/memobj-r0drv-linux.c  | 99 +++++++++++++++++--
 2 files changed, 115 insertions(+), 14 deletions(-)

diff --git a/trunk/include/iprt/memobj.h b/trunk/include/iprt/memobj.h
index 2510d8be52..4925315db6 100644
--- a/trunk/include/iprt/memobj.h
+++ b/trunk/include/iprt/memobj.h
@@ -127,7 +127,10 @@ RTR0DECL(int) RTR0MemObjFree(RTR0MEMOBJ MemObj, bool fFreeMappings);
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  */
 #define RTR0MemObjAllocPage(pMemObj, cb, fExecutable) \
     RTR0MemObjAllocPageTag((pMemObj), (cb), (fExecutable), RTMEM_TAG)
@@ -140,7 +143,10 @@ RTR0DECL(int) RTR0MemObjFree(RTR0MEMOBJ MemObj, bool fFreeMappings);
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  * @param   pszTag          Allocation tag used for statistics and such.
  */
 RTR0DECL(int) RTR0MemObjAllocPageTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecutable, const char *pszTag);
@@ -154,7 +160,10 @@ RTR0DECL(int) RTR0MemObjAllocPageTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecu
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  */
 #define RTR0MemObjAllocLow(pMemObj, cb, fExecutable) \
     RTR0MemObjAllocLowTag((pMemObj), (cb), (fExecutable), RTMEM_TAG)
@@ -168,7 +177,10 @@ RTR0DECL(int) RTR0MemObjAllocPageTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecu
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  * @param   pszTag          Allocation tag used for statistics and such.
  */
 RTR0DECL(int) RTR0MemObjAllocLowTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecutable, const char *pszTag);
@@ -182,7 +194,10 @@ RTR0DECL(int) RTR0MemObjAllocLowTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecut
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  */
 #define RTR0MemObjAllocCont(pMemObj, cb, fExecutable) \
     RTR0MemObjAllocContTag((pMemObj), (cb), (fExecutable), RTMEM_TAG)
@@ -196,7 +211,10 @@ RTR0DECL(int) RTR0MemObjAllocLowTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecut
  * @returns IPRT status code.
  * @param   pMemObj         Where to store the ring-0 memory object handle.
  * @param   cb              Number of bytes to allocate. This is rounded up to nearest page.
- * @param   fExecutable     Flag indicating whether it should be permitted to executed code in the memory object.
+ * @param   fExecutable     Flag indicating whether it should be permitted to
+ *                          executed code in the memory object.  The user must
+ *                          use RTR0MemObjProtect after initialization the
+ *                          allocation to actually make it executable.
  * @param   pszTag          Allocation tag used for statistics and such.
  */
 RTR0DECL(int) RTR0MemObjAllocContTag(PRTR0MEMOBJ pMemObj, size_t cb, bool fExecutable, const char *pszTag);
diff --git a/trunk/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c b/trunk/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
index b2c9dcdea8..e42fe255b6 100644
--- a/trunk/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
+++ b/trunk/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
@@ -92,7 +92,7 @@
 *   Structures and Typedefs                                                                                                      *
 *********************************************************************************************************************************/
 /**
- * The Darwin version of the memory object structure.
+ * The Linux version of the memory object structure.
  */
 typedef struct RTR0MEMOBJLNX
 {
@@ -105,11 +105,20 @@ typedef struct RTR0MEMOBJLNX
     bool                fExecutable;
     /** Set if we've vmap'ed the memory into ring-0. */
     bool                fMappedToRing0;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+    /** Return from alloc_vm_area() that we now need to use for executable
+     *  memory. */
+    struct vm_struct   *pArea;
+    /** PTE array that goes along with pArea (must be freed). */
+    pte_t             **papPtesForArea;
+#endif
     /** The pages in the apPages array. */
     size_t              cPages;
     /** Array of struct page pointers. (variable size) */
     struct page        *apPages[1];
-} RTR0MEMOBJLNX, *PRTR0MEMOBJLNX;
+} RTR0MEMOBJLNX;
+/** Pointer to the linux memory object. */
+typedef RTR0MEMOBJLNX *PRTR0MEMOBJLNX;
 
 
 static void rtR0MemObjLinuxFreePages(PRTR0MEMOBJLNX pMemLnx);
@@ -535,15 +544,49 @@ static int rtR0MemObjLinuxVMap(PRTR0MEMOBJLNX pMemLnx, bool fExecutable)
             pgprot_val(fPg) |= _PAGE_NX;
 # endif
 
+# if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+        if (fExecutable)
+        {
+            pte_t **papPtes = (pte_t **)kmalloc_array(pMemLnx->cPages, sizeof(papPtes[0]), GFP_KERNEL);
+            if (papPtes)
+            {
+                pMemLnx->pArea = alloc_vm_area(pMemLnx->Core.cb, papPtes); /* Note! pArea->nr_pages is not set. */
+                if (pMemLnx->pArea)
+                {
+                    size_t i;
+                    Assert(pMemLnx->pArea->size >= pMemLnx->Core.cb);   /* Note! includes guard page. */
+                    Assert(pMemLnx->pArea->addr);
+#  ifdef _PAGE_NX
+                    pgprot_val(fPg) |= _PAGE_NX; /* Uses RTR0MemObjProtect to clear NX when memory ready, W^X fashion. */
+#  endif
+                    pMemLnx->papPtesForArea = papPtes;
+                    for (i = 0; i < pMemLnx->cPages; i++)
+                        *papPtes[i] = mk_pte(pMemLnx->apPages[i], fPg);
+                    pMemLnx->Core.pv = pMemLnx->pArea->addr;
+                    pMemLnx->fMappedToRing0 = true;
+                }
+                else
+                {
+                    kfree(papPtes);
+                    rc = VERR_MAP_FAILED;
+                }
+            }
+            else
+                rc = VERR_MAP_FAILED;
+        }
+        else
+# endif
+        {
 # ifdef VM_MAP
-        pMemLnx->Core.pv = vmap(&pMemLnx->apPages[0], pMemLnx->cPages, VM_MAP, fPg);
+            pMemLnx->Core.pv = vmap(&pMemLnx->apPages[0], pMemLnx->cPages, VM_MAP, fPg);
 # else
-        pMemLnx->Core.pv = vmap(&pMemLnx->apPages[0], pMemLnx->cPages, VM_ALLOC, fPg);
+            pMemLnx->Core.pv = vmap(&pMemLnx->apPages[0], pMemLnx->cPages, VM_ALLOC, fPg);
 # endif
-        if (pMemLnx->Core.pv)
-            pMemLnx->fMappedToRing0 = true;
-        else
-            rc = VERR_MAP_FAILED;
+            if (pMemLnx->Core.pv)
+                pMemLnx->fMappedToRing0 = true;
+            else
+                rc = VERR_MAP_FAILED;
+        }
 #else   /* < 2.4.22 */
         rc = VERR_NOT_SUPPORTED;
 #endif
@@ -569,6 +612,22 @@ static int rtR0MemObjLinuxVMap(PRTR0MEMOBJLNX pMemLnx, bool fExecutable)
 static void rtR0MemObjLinuxVUnmap(PRTR0MEMOBJLNX pMemLnx)
 {
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 4, 22)
+# if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+    if (pMemLnx->pArea)
+    {
+#  if 0
+        pte_t **papPtes = pMemLnx->papPtesForArea;
+        size_t  i;
+        for (i = 0; i < pMemLnx->cPages; i++)
+            *papPtes[i] = 0;
+#  endif
+        free_vm_area(pMemLnx->pArea);
+        kfree(pMemLnx->papPtesForArea);
+        pMemLnx->pArea = NULL;
+        pMemLnx->papPtesForArea = NULL;
+    }
+    else
+# endif
     if (pMemLnx->fMappedToRing0)
     {
         Assert(pMemLnx->Core.pv);
@@ -1437,6 +1496,7 @@ DECLHIDDEN(int) rtR0MemObjNativeMapKernel(PPRTR0MEMOBJINTERNAL ppMem, RTR0MEMOBJ
              * Use vmap - 2.4.22 and later.
              */
             pgprot_t fPg = rtR0MemObjLinuxConvertProt(fProt, true /* kernel */);
+            /** @todo We don't really care too much for EXEC here... 5.8 always adds NX. */
             Assert(((offSub + cbSub) >> PAGE_SHIFT) <= pMemLnxToMap->cPages);
 # ifdef VM_MAP
             pMemLnx->Core.pv = vmap(&pMemLnxToMap->apPages[offSub >> PAGE_SHIFT], cbSub >> PAGE_SHIFT, VM_MAP, fPg);
@@ -1768,6 +1828,29 @@ DECLHIDDEN(int) rtR0MemObjNativeMapUser(PPRTR0MEMOBJINTERNAL ppMem, RTR0MEMOBJ p
 
 DECLHIDDEN(int) rtR0MemObjNativeProtect(PRTR0MEMOBJINTERNAL pMem, size_t offSub, size_t cbSub, uint32_t fProt)
 {
+# if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+    /*
+     * Currently only supported when we've got addresses PTEs from the kernel.
+     */
+    PRTR0MEMOBJLNX pMemLnx = (PRTR0MEMOBJLNX)pMem;
+    if (pMemLnx->pArea && pMemLnx->papPtesForArea)
+    {
+        pgprot_t const  fPg     = rtR0MemObjLinuxConvertProt(fProt, true /*fKernel*/);
+        size_t const    cPages  = (offSub + cbSub) >> PAGE_SHIFT;
+        pte_t         **papPtes = pMemLnx->papPtesForArea;
+        size_t          i;
+
+        for (i = offSub >> PAGE_SHIFT; i < cPages; i++)
+        {
+            set_pte(papPtes[i], mk_pte(pMemLnx->apPages[i], fPg));
+        }
+        preempt_disable();
+        __flush_tlb_all();
+        preempt_enable();
+        return VINF_SUCCESS;
+    }
+# endif
+
     NOREF(pMem);
     NOREF(offSub);
     NOREF(cbSub);
